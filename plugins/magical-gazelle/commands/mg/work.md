---
name: mg:work
description: Execute work plans efficiently while maintaining quality and finishing features
argument-hint: "[plan file, specification, or todo file path]"
---

# Work Plan Execution Command

Execute a work plan efficiently while maintaining quality and finishing features.

## Introduction

This command takes a work document (plan, specification, or todo file) and executes it systematically. The focus is on **shipping complete features** by understanding requirements quickly, following existing patterns, and maintaining quality throughout.

## Input Document

<input_document> #$ARGUMENTS </input_document>

## Execution Workflow

### Phase 1: Quick Start

1. **Read Plan and Clarify**
   - Read the work document completely
   - Review any references or links provided in the plan
   - If anything is unclear or ambiguous, ask clarifying questions now
   - Get user approval to proceed
   - **Do not skip this** - better to ask questions now than build the wrong thing

2. **Setup Environment**

   First, check the current branch:

   ```bash
   current_branch=$(git branch --show-current)
   default_branch=$(git symbolic-ref refs/remotes/origin/HEAD 2>/dev/null | sed 's@^refs/remotes/origin/@@')

   # Fallback if remote HEAD isn't set
   if [ -z "$default_branch" ]; then
     default_branch=$(git rev-parse --verify origin/main >/dev/null 2>&1 && echo "main" || echo "master")
   fi
   ```

   **If already on a feature branch** (not the default branch):
   - Ask: "Continue working on `[current_branch]`, or create a new branch?"
   - If continuing, proceed to step 3
   - If creating new, follow Option A or B below

   **If on the default branch**, choose how to proceed:

   **Option A: Create a new branch** (default)

   ```bash
   git pull origin [default_branch]
   git checkout -b feature-branch-name
   ```

   Use a meaningful name based on the work (e.g., `feat/user-authentication`, `fix/email-validation`).

   **Option B: Use a worktree** (for parallel development)

   ```bash
   git pull origin [default_branch]
   git worktree add ../$(basename $(pwd))-feature-name -b feature-branch-name [default_branch]
   cd ../$(basename $(pwd))-feature-name
   # Run worktree-setup.sh if it exists, otherwise handle .env/deps manually
   test -f worktree-setup.sh && bash worktree-setup.sh
   ```

   Use when working on multiple features simultaneously. Creates a sibling directory with its own checkout.

   **Option C: Continue on the default branch**
   - Requires explicit user confirmation
   - Only proceed after user explicitly says "yes, commit to [default_branch]"
   - Never commit directly to the default branch without explicit permission

3. **Create Todo List**
   - Use TodoWrite to break plan into actionable tasks
   - Include dependencies between tasks
   - Prioritize based on what needs to be done first
   - **Create a dedicated test task for each item in the plan's Testing section** (Must Test + Edge Cases)
   - Keep tasks specific and completable

### Phase 2: Execute

1. **Task Execution Loop**

   For each task in priority order:

   ```
   while (tasks remain):
     - Mark task as in_progress in TodoWrite
     - Read any referenced files from the plan
     - Look for similar patterns in codebase
     - Implement following existing conventions
     - Write tests (cover plan's Testing section items + any new behavior)
     - Run tests after changes
     - Mark task as completed in TodoWrite
     - Mark off the corresponding checkbox in the plan file ([ ] → [x])
     - Evaluate for incremental commit (see below)
   ```

   **IMPORTANT**: Always update the original plan document by checking off completed items. Use the Edit tool to change `- [ ]` to `- [x]` for each task you finish. This keeps the plan as a living document showing progress and ensures no checkboxes are left unchecked.

2. **Incremental Commits**

   After completing each task, evaluate whether to create an incremental commit:

   | Commit when...                                    | Don't commit when...                |
   | ------------------------------------------------- | ----------------------------------- |
   | Logical unit complete (model, service, component) | Small part of a larger unit         |
   | Tests pass + meaningful progress                  | Tests failing                       |
   | About to switch contexts (backend → frontend)     | Purely scaffolding with no behavior |
   | About to attempt risky/uncertain changes          | Would need a "WIP" commit message   |

   **Heuristic:** "Can I write a commit message that describes a complete, valuable change? If yes, commit. If the message would be 'WIP' or 'partial X', wait."

   **Commit workflow:**

   ```bash
   # 1. Verify tests pass (use project's test command)
   # Examples: uv run pytest, npm test, go test, etc.

   # 2. Stage only files related to this logical unit (not `git add .`)
   git add <files related to this logical unit>

   # 3. Commit with conventional message
   git commit -m "feat(scope): description of this unit"
   ```

   **Handling merge conflicts:** If conflicts arise during rebasing or merging, resolve them immediately. Incremental commits make conflict resolution easier since each commit is small and focused.

   **Note:** All commits use clean conventional messages — no attribution footers or generated-by notes.

3. **Follow Existing Patterns**
   - The plan should reference similar code - read those files first
   - Match naming conventions exactly
   - Reuse existing components where possible
   - Follow project coding standards (see CLAUDE.md)
   - When in doubt, grep for similar implementations

4. **Write and Run Tests**
   - **Always write tests for new functionality** — this is not optional. If the plan has a Testing section, implement every test listed there. If the plan lacks a Testing section, identify and write tests yourself.
   - Write tests alongside implementation, not after. When you implement a service, write its tests in the same task before moving on.
   - Run the full relevant test suite after each significant change
   - Fix failures immediately
   - For bug fixes: write the failing test first, then fix the bug

5. **Figma Design Sync** (if applicable)

   For UI work with Figma designs:
   - Implement components following design specs
   - Use design-reviewer agent iteratively to compare
   - Fix visual differences identified
   - Repeat until implementation matches design

6. **Track Progress**
   - Keep TodoWrite updated as you complete tasks
   - Note any blockers or unexpected discoveries
   - Create new tasks if scope expands
   - Keep user informed of major milestones

### Phase 3: Quality Check

1. **Run Core Quality Checks**

   Always run before submitting:

   ```bash
   # Run full test suite (use project's test command)
   # Examples: uv run pytest, npm test, go test, etc.

   # Run linting (per CLAUDE.md)
   # Examples: uv run ruff check ., npm run lint, etc.
   ```

2. **Browser Verification** (For UI/frontend changes)

   If changes touch views, templates, components, stylesheets, or frontend code, verify in a real browser. Skip this step for backend-only changes (models, migrations, APIs with no UI).

   **Check for flow manifest:**
   ```bash
   test -f .claude/browser-flows.yml && echo "Manifest found" || echo "No manifest"
   ```

   **If manifest exists:**
   - Read `.claude/browser-flows.yml` for server URL, auth config, and routes
   - Test routes affected by the changed files
   - Run any flows that touch modified components

   **If no manifest:**
   - Map changed files to routes (same logic as `/smoke-test`)
   - Open each affected route and verify it loads correctly

   **For each route, verify:**
   ```bash
   agent-browser open [server-url][route]
   agent-browser snapshot -i                    # Page renders with expected content
   agent-browser execute "JSON.stringify(window.__errors || [])"  # No console errors
   agent-browser screenshot browser-screenshots/verify-[route-name].png
   ```

   - Page loads without errors
   - Expected content is present (headings, forms, data)
   - No JavaScript console errors
   - No visible error messages or broken layouts

   **On failure:** Report the issue to the user immediately. Do not proceed to PR creation with broken pages.

   **CRITICAL:** Use `agent-browser` CLI commands only. Do NOT use `mcp__claude-in-chrome__*` tools.

3. **Consider Reviewer Agents** (Optional)

   Use for complex, risky, or large changes. Read agents from `magical-gazelle.local.md` frontmatter (`review_agents`). If no settings file, invoke the `setup` skill to create one.

   Run configured agents in parallel with Task tool. Present findings and address critical issues.

4. **Final Validation**
   - All TodoWrite tasks marked completed
   - All items in the plan's Testing section have corresponding tests
   - All tests pass
   - Linting passes
   - Code follows existing patterns
   - Figma designs match (if applicable)
   - Browser verification passed (if UI changes)
   - No console errors or warnings

5. **Prepare Operational Validation Plan** (REQUIRED)
   - Add a `## Post-Deploy Monitoring & Validation` section to the PR description for every change.
   - Include concrete:
     - Log queries/search terms
     - Metrics or dashboards to watch
     - Expected healthy signals
     - Failure signals and rollback/mitigation trigger
     - Validation window and owner
   - If there is truly no production/runtime impact, still include the section with: `No additional operational monitoring required` and a one-line reason.

### Phase 4: Ship It

1. **Create Commit**

   ```bash
   git add .
   git status  # Review what's being committed
   git diff --staged  # Check the changes

   # Commit with conventional format
   git commit -m "$(cat <<'EOF'
   feat(scope): description of what and why

   Brief explanation if needed.
   EOF
   )"
   ```

2. **Capture and Upload Screenshots for UI Changes** (REQUIRED for any UI work)

   For **any** design changes, new views, or UI modifications, you MUST capture and upload screenshots:

   **Step 1: Start dev server** (if not running)

   ```bash
   # Use project's dev server command (per CLAUDE.md)
   ```

   **Step 2: Capture screenshots with agent-browser CLI**

   ```bash
   mkdir -p browser-screenshots && grep -qxF 'browser-screenshots/' .gitignore 2>/dev/null || echo 'browser-screenshots/' >> .gitignore
   agent-browser open http://localhost:[port]/[route]
   agent-browser snapshot -i
   agent-browser screenshot browser-screenshots/output.png
   ```

   See the `agent-browser` skill for detailed usage.

   **Step 3: Upload using imgup skill**

   ```bash
   skill: imgup
   # Then upload each screenshot:
   imgup -h pixhost browser-screenshots/output.png  # pixhost works without API key
   # Alternative hosts: catbox, imagebin, beeimg
   ```

   **What to capture:**
   - **New screens**: Screenshot of the new UI
   - **Modified screens**: Before AND after screenshots
   - **Design implementation**: Screenshot showing Figma design match

   **IMPORTANT**: Always include uploaded image URLs in PR description. This provides visual context for reviewers and documents the change.

3. **Create Pull Request**

   ```bash
   git push -u origin feature-branch-name

   gh pr create --title "feat(scope): description" --body "$(cat <<'EOF'
   ## Summary
   - What was built
   - Why it was needed
   - Key decisions made

   ## Testing
   - Tests added/modified
   - Manual testing performed

   ## Post-Deploy Monitoring & Validation
   - **What to monitor/search**
     - Logs:
     - Metrics/Dashboards:
   - **Validation checks (queries/commands)**
     - `command or query here`
   - **Expected healthy behavior**
     - Expected signal(s)
   - **Failure signal(s) / rollback trigger**
     - Trigger + immediate action
   - **Validation window & owner**
     - Window:
     - Owner:
   - **If no operational impact**
     - `No additional operational monitoring required: <reason>`

   ## Before / After Screenshots
   | Before | After |
   |--------|-------|
   | ![before](URL) | ![after](URL) |

   ## Figma Design
   [Link if applicable]

   EOF
   )"
   ```

4. **Update Plan Status**

   If the input document has YAML frontmatter with a `status` field, update it to `completed`:

   ```
   status: active  →  status: completed
   ```

5. **Notify User**
   - Summarize what was completed
   - Link to PR
   - Note any follow-up work needed
   - Suggest next steps if applicable

---

## Swarm Mode (Optional)

For complex plans with multiple independent workstreams, enable swarm mode for parallel execution with coordinated agents.

### When to Use Swarm Mode

| Use Swarm Mode when...                                  | Use Standard Mode when...      |
| ------------------------------------------------------- | ------------------------------ |
| Plan has 5+ independent tasks                           | Plan is linear/sequential      |
| Multiple specialists needed (review + test + implement) | Single-focus work              |
| Want maximum parallelism                                | Simpler mental model preferred |
| Large feature with clear phases                         | Small feature or bug fix       |

### Enabling Swarm Mode

To trigger swarm execution, say:

> "Make a Task list and launch an army of agent swarm subagents to build the plan"

Or explicitly request: "Use swarm mode for this work"

### Swarm Workflow

When swarm mode is enabled, the workflow changes:

1. **Create Team**

   ```
   Teammate({ operation: "spawnTeam", team_name: "work-{timestamp}" })
   ```

2. **Create Task List with Dependencies**
   - Parse plan into TaskCreate items
   - Set up blockedBy relationships for sequential dependencies
   - Independent tasks have no blockers (can run in parallel)

3. **Spawn Specialized Teammates**

   ```
   Task({
     team_name: "work-{timestamp}",
     name: "implementer",
     subagent_type: "general-purpose",
     prompt: "Claim implementation tasks, execute, mark complete",
     run_in_background: true
   })

   Task({
     team_name: "work-{timestamp}",
     name: "tester",
     subagent_type: "general-purpose",
     prompt: "Claim testing tasks, run tests, mark complete",
     run_in_background: true
   })
   ```

4. **Coordinate and Monitor**
   - Team lead monitors task completion
   - Spawn additional workers as phases unblock
   - Handle plan approval if required

5. **Cleanup**
   ```
   Teammate({ operation: "requestShutdown", target_agent_id: "implementer" })
   Teammate({ operation: "requestShutdown", target_agent_id: "tester" })
   Teammate({ operation: "cleanup" })
   ```

See the `orchestrating-swarms` skill for detailed swarm patterns and best practices.

---

## Key Principles

### Start Fast, Execute Faster

- Get clarification once at the start, then execute
- Don't wait for perfect understanding - ask questions and move
- The goal is to **finish the feature**, not create perfect process

### The Plan is Your Guide

- Work documents should reference similar code and patterns
- Load those references and follow them
- Don't reinvent - match what exists

### Tests Ship With Features

- Every new behavior gets a test — write tests alongside implementation, not after
- Use the plan's Testing section as your checklist: implement every must-test and edge case listed
- For bug fixes: write the failing test first, then fix the code
- Run tests after each change, fix failures immediately

### Quality is Built In

- Follow existing patterns
- Run linting before pushing
- Use reviewer agents for complex/risky changes only

### Ship Complete Features

- Mark all tasks completed before moving on
- Don't leave features 80% done
- A finished feature that ships beats a perfect feature that doesn't

## Quality Checklist

Before creating PR, verify:

- [ ] All clarifying questions asked and answered
- [ ] All TodoWrite tasks marked completed
- [ ] Tests written for all new functionality (plan's Testing section fully covered)
- [ ] Tests pass (run project's test command)
- [ ] Linting passes (run linter per CLAUDE.md)
- [ ] Code follows existing patterns
- [ ] Figma designs match implementation (if applicable)
- [ ] Browser verification passed — affected pages load without errors (for UI changes)
- [ ] Before/after screenshots captured and uploaded (for UI changes)
- [ ] Commit messages follow conventional format
- [ ] PR description includes Post-Deploy Monitoring & Validation section (or explicit no-impact rationale)
- [ ] PR description includes summary, testing notes, and screenshots

## When to Use Reviewer Agents

**Don't use by default.** Use reviewer agents only when:

- Large refactor affecting many files (10+)
- Security-sensitive changes (authentication, permissions, data access)
- Performance-critical code paths
- Complex algorithms or business logic
- User explicitly requests thorough review

For most features: tests + linting + following patterns is sufficient.

## Common Pitfalls to Avoid

- **Analysis paralysis** - Don't overthink, read the plan and execute
- **Skipping clarifying questions** - Ask now, not after building wrong thing
- **Ignoring plan references** - The plan has links for a reason
- **Skipping tests or deferring them** - Write tests alongside implementation, not after
- **Forgetting TodoWrite** - Track progress or lose track of what's done
- **80% done syndrome** - Finish the feature, don't move on early
- **Over-reviewing simple changes** - Save reviewer agents for complex work
